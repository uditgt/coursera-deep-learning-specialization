{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation\n",
    "\n",
    "* Neural Machine Translation (NMT) model to translate human-readable dates (\"25th of June, 2009\") into machine-readable dates (\"2009-06-25\")\n",
    "* Using an attention model, one of the most sophisticated sequence-to-sequence models\n",
    "* While the model can be used to translate from one language to another - due to lack of compute resources and training data, we use a simpler example\n",
    "\n",
    "## Attention Model\n",
    "\n",
    "The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. Below diagrams show how the model works. \n",
    "* The diagram on the left shows the attention model. \n",
    "* The diagram on the right shows what one \"attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "* Attention variables $\\alpha^{\\langle t, t' \\rangle}$ are used to compute the context variable $context^{\\langle t \\rangle}$ for each o/p timestep ($t=1, \\ldots, T_y$). \n",
    "\n",
    "<table>\n",
    "<td><img src=\"images/attn_model.png\" style=\"width:500;height:400px;\"> <br></td> \n",
    "<td><img src=\"images/attn_mechanism.png\" style=\"width:500;height:400px;\"> <br></td> \n",
    "</table>\n",
    "<caption><center>Neural machine translation with attention</center></caption>\n",
    "\n",
    "### Pre-attention and Post-attention LSTMs on both sides of the attention mechanism\n",
    "- There are two separate LSTMs in this model (see diagram on the left): pre-attention and post-attention LSTMs.\n",
    "  - **Pre-attention Bi-LSTM** comes *before* the attention mechanism and goes through $T_x$ time steps\n",
    "  - **Post-attention LSTM** comes *after* the attention mechanism and goes through $T_y$ time steps. \n",
    "    - Post-attention LSTM passes the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ from one time step to the next.\n",
    "    - Unlike text generation examples, the post-attention LSTM at time $t$ does not take $y^{\\langle t-1 \\rangle}$ as input.\n",
    "    - Post-attention LSTM at time 't' only takes the hidden state $s^{\\langle t\\rangle}$ and cell state $c^{\\langle t\\rangle}$ as input. \n",
    "    - We have designed the model this way because unlike language generation (where adjacent characters are highly correlated) there isn't as strong a dependency between the previous character and the next character in a YYYY-MM-DD date.\n",
    "    \n",
    "### Computing \"Energies\" $e^{\\langle t, t' \\rangle}$ as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$\n",
    "- Note that the diagram doesn't explicitly show variable $e^{\\langle t, t' \\rangle}$, but $e^{\\langle t, t' \\rangle}$ **is above the Dense layer and below the Softmax layer**\n",
    "- $s^{\\langle t-1 \\rangle}$ is the hidden state of the post-attention LSTM\n",
    "- $a^{\\langle t' \\rangle}$ is the hidden state of the pre-attention LSTM.\n",
    "- $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ are fed into a simple neural network, which learns the function to output $e^{\\langle t, t' \\rangle}$.\n",
    "- $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $\\alpha^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from faker import Faker\n",
    "from tqdm import tqdm    # prints a dynamically updating progressbar\n",
    "from babel.dates import format_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dates in proper and improper formats\n",
    "\n",
    "FORMATS = ['short','medium','long','full','full','full','full','full','full','full','full',\n",
    "           'full','full','d MMM YYY','d MMMM YYY','dd MMM YYY','d MMM, YYY','d MMMM, YYY',\n",
    "           'dd, MMM YYY','d MM YY','d MMMM YYY','MMMM d YYY','MMMM d, YYY','dd.MM.YY']\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def load_date():\n",
    "    dt = fake.date_object()\n",
    "    human_readable = format_date(dt, format=random.choice(FORMATS),locale='en_US')\n",
    "    human_readable = human_readable.lower().replace(',','')\n",
    "    machine_readable = dt.isoformat()\n",
    "        \n",
    "    return human_readable, machine_readable, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(m):\n",
    "    \"\"\"Loads a dataset with m examples and vocabularies\"\"\"    \n",
    "    human_vocab = set()\n",
    "    machine_vocab = set()\n",
    "    dataset = []\n",
    "\n",
    "    for i in tqdm(range(m)):\n",
    "        h, m, _ = load_date()\n",
    "        dataset.append((h, m))\n",
    "        human_vocab.update(tuple(h))\n",
    "        machine_vocab.update(tuple(m))\n",
    "    \n",
    "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'],\n",
    "                     list(range(len(human_vocab) + 2))))\n",
    "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
    "    machine = {v:k for k,v in inv_machine.items()}\n",
    " \n",
    "    return dataset, human, machine, inv_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 18673.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# human_vocab: dictionary mapping characters used in human readable dates to an integer index.\n",
    "# machine_vocab: dictionary mapping characters used in machine readable dates to an integer index\n",
    "\n",
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('24 nov 1984', '1984-11-24'),\n",
       " ('27 jul 1993', '1993-07-27'),\n",
       " ('tuesday july 11 1972', '1972-07-11'),\n",
       " ('november 21 1997', '1997-11-21'),\n",
       " ('may 29 2014', '2014-05-29'),\n",
       " ('17 may 1982', '1982-05-17'),\n",
       " ('19 mar 2002', '2002-03-19'),\n",
       " ('wednesday march 10 1982', '1982-03-10'),\n",
       " ('friday january 13 2017', '2017-01-13'),\n",
       " ('tuesday august 7 2007', '2007-08-07')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_vocab #, machine_vocab, inv_machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i[0]) for i in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30   # maximum length of the human readable date\n",
    "Ty = 10   # \"YYYY-MM-DD\" is 10 characters long.\n",
    "\n",
    "\n",
    "def string_to_int(string, maxLen, vocab):\n",
    "    \"\"\" converts string to integers using vocab dictionary \"\"\"\n",
    "    string = string.lower().replace(',','')\n",
    "    if len(string) > maxLen:\n",
    "        string = string[:maxLen]\n",
    "    else:\n",
    "        string = list(string) + ['<pad>'] * (maxLen - len(string))\n",
    "        \n",
    "    return list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
    "    \n",
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y =          [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "    \n",
    "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
    "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, np.array(Y), Xoh, Yoh\n",
    "\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 24 nov 1984\n",
      "Target date: 1984-11-24\n",
      "\n",
      "Source after preprocessing: [ 5  7  0 25 26 32  0  4 12 11  7 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing: [ 2 10  9  5  0  2  2  0  3  5]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing:\", X[index])\n",
    "print(\"Target after preprocessing:\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Function for Attention Model\n",
    "\n",
    "#### `one_step_attention`\n",
    "* The inputs to the one_step_attention at time step $t$ are:\n",
    "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$: all hidden states of the pre-attention Bi-LSTM.\n",
    "    - $s^{<t-1>}$: the previous hidden state of the post-attention LSTM \n",
    "* one_step_attention computes:\n",
    "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights\n",
    "    - $context^{ \\langle t \\rangle }$: the context vector:\n",
    "    \n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}$$ \n",
    "\n",
    "\n",
    "* The function `model()` will call the layers in `one_step_attention()` $T_y$ times using a for-loop.\n",
    "* It is important that **all $T_y$ copies have the same weights. It should not reinitialize the weights every time.**\n",
    "* To implement layers with shareable weights in Keras:\n",
    "    1. Define the layer objects in a variable scope that is outside of function.E.g. defining the objects as global variables would work.\n",
    "    2. Call these objects when propagating the input.\n",
    "\n",
    "References:\n",
    "* [RepeatVector()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector) : var_repeated = repeat_layer(var1)\n",
    "* [Concatenate()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate) : concatenated_vars = concatenate_layer([var1,var2,var3])\n",
    "* [Dense()](https://keras.io/layers/core/#dense) : var_out = dense_layer(var_in)\n",
    "* [Activation()](https://keras.io/layers/core/#activation): activation = activation_layer(var_in)\n",
    "* [Dot()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot) : dot_product = dot_layer([var1,var2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments: x (tensor), axis (axis along which the softmax normalization is applied)\n",
    "    # Raises: ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    s_prev = repeator(s_prev)           # repeat s_prev to become (m, Tx, n_s) so it can concatenate with all hidden states \"a\"\n",
    "    concat = concatenator([a, s_prev])  # concatenate\n",
    "    e = densor1(concat)                 # each 't' is propagated through a Dense(10) layer to get (m, Tx, 10) [self note]\n",
    "    energies = densor2(e)               # (m, Tx, 1) [self note]\n",
    "    alphas = activator(energies)        # (m, Tx, 1)\n",
    "    context = dotor([alphas, a])        # (m, 1, 2*n_a)\n",
    "    \n",
    "#     print(s_prev.shape)\n",
    "#     print(concat.shape)\n",
    "#     print(e.shape)\n",
    "#     print(energies.shape)\n",
    "#     print(alphas.shape)\n",
    "#     print(context.shape)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `modelf()`\n",
    "\n",
    "* `modelf` first runs the input through a Bi-LSTM to get $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$. \n",
    "* Then, `modelf` calls `one_step_attention()` $T_y$ times using a `for` loop.  At each iteration of this loop:\n",
    "    - It gives the computed context vector $context^{<t>}$ to the post-attention LSTM.\n",
    "    - It runs the output of the post-attention LSTM through a dense layer with softmax activation.\n",
    "    - The softmax generates a prediction $\\hat{y}^{<t>}$.\n",
    "    \n",
    "Again, we have defined global layers that will share weights to be used in `modelf()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32   # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_s = 64   # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "\n",
    "# Post attention LSTM cell\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
    "    # for the decoder LSTM with shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    # Define your pre-attention Bi-LSTM\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    # Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Perform one step of the attention mechanism to get the context vector at t\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Post-attention LSTM cell to \"context\" vector. (initial_state = [hidden state, cell state])\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # Dense layer to the hidden state output of the post-attention LSTM\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Gather outputs\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Create model instance\n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 30, 37)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[15][0]                      \n",
      "                                                                 lstm[16][0]                      \n",
      "                                                                 lstm[17][0]                      \n",
      "                                                                 lstm[18][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[10][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[11][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[12][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[13][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[14][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[15][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[16][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[17][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[18][0]             \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector[19][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 10)       1290        concatenate[10][0]               \n",
      "                                                                 concatenate[11][0]               \n",
      "                                                                 concatenate[12][0]               \n",
      "                                                                 concatenate[13][0]               \n",
      "                                                                 concatenate[14][0]               \n",
      "                                                                 concatenate[15][0]               \n",
      "                                                                 concatenate[16][0]               \n",
      "                                                                 concatenate[17][0]               \n",
      "                                                                 concatenate[18][0]               \n",
      "                                                                 concatenate[19][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 1)        11          dense[10][0]                     \n",
      "                                                                 dense[11][0]                     \n",
      "                                                                 dense[12][0]                     \n",
      "                                                                 dense[13][0]                     \n",
      "                                                                 dense[14][0]                     \n",
      "                                                                 dense[15][0]                     \n",
      "                                                                 dense[16][0]                     \n",
      "                                                                 dense[17][0]                     \n",
      "                                                                 dense[18][0]                     \n",
      "                                                                 dense[19][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "                                                                 dense_1[16][0]                   \n",
      "                                                                 dense_1[17][0]                   \n",
      "                                                                 dense_1[18][0]                   \n",
      "                                                                 dense_1[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 64)        0           attention_weights[10][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[14][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[15][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[16][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[17][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[18][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[19][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 64), (None,  33024       dot[10][0]                       \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot[11][0]                       \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[10][2]                      \n",
      "                                                                 dot[12][0]                       \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[11][2]                      \n",
      "                                                                 dot[13][0]                       \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[12][2]                      \n",
      "                                                                 dot[14][0]                       \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[13][2]                      \n",
      "                                                                 dot[15][0]                       \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[14][2]                      \n",
      "                                                                 dot[16][0]                       \n",
      "                                                                 lstm[15][0]                      \n",
      "                                                                 lstm[15][2]                      \n",
      "                                                                 dot[17][0]                       \n",
      "                                                                 lstm[16][0]                      \n",
      "                                                                 lstm[16][2]                      \n",
      "                                                                 dot[18][0]                       \n",
      "                                                                 lstm[17][0]                      \n",
      "                                                                 lstm[17][2]                      \n",
      "                                                                 dot[19][0]                       \n",
      "                                                                 lstm[18][0]                      \n",
      "                                                                 lstm[18][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11)           715         lstm[10][0]                      \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[15][0]                      \n",
      "                                                                 lstm[16][0]                      \n",
      "                                                                 lstm[17][0]                      \n",
      "                                                                 lstm[18][0]                      \n",
      "                                                                 lstm[19][0]                      \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, decay=0.01),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('pretrainedmodel/attention_model_dates/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025CE6EE5558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025CE6EE5558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "source: 3 May 1979\n",
      "output: 1979-05-33 \n",
      "\n",
      "source: 5 April 09\n",
      "output: 2009-04-05 \n",
      "\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-20 \n",
      "\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10 \n",
      "\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    #print(source)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_string(ints, inv_vocab):\n",
    "    return [inv_vocab[i] for i in ints]\n",
    "\n",
    "def plot_attention_map(modelx, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 7):\n",
    "    \"\"\"\n",
    "    Plot the attention map.\n",
    "  \n",
    "    \"\"\"\n",
    "    attention_map = np.zeros((10, 30))\n",
    "    human_vocab_size = 37\n",
    "    \n",
    "    layer = modelx.get_layer('attention_weights')\n",
    "    Ty, Tx = attention_map.shape\n",
    "    \n",
    "    # Well, this is cumbersome but this version of tensorflow-keras has a bug that affects the \n",
    "    # reuse of layers in a model with the functional API. \n",
    "    # So, I have to recreate the model based on the functional \n",
    "    # components and connect then one by one.\n",
    "    # ideally it can be done simply like this:\n",
    "    # layer = modelx.layers[num]\n",
    "    # f = Model(modelx.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
    "    #\n",
    "    \n",
    "    X = modelx.inputs[0] \n",
    "    s0 = modelx.inputs[1] \n",
    "    c0 = modelx.inputs[2] \n",
    "    s = s0\n",
    "    c = s0\n",
    "    \n",
    "    a = modelx.layers[2](X)  \n",
    "    outputs = []\n",
    "\n",
    "    for t in range(Ty):\n",
    "        s_prev = s\n",
    "        s_prev = modelx.layers[3](s_prev)\n",
    "        concat = modelx.layers[4]([a, s_prev]) \n",
    "        e = modelx.layers[5](concat) \n",
    "        energies = modelx.layers[6](e) \n",
    "        alphas = modelx.layers[7](energies) \n",
    "        context = modelx.layers[8]([alphas, a])\n",
    "        s, _, c = modelx.layers[10](context, initial_state = [s, c]) \n",
    "        outputs.append(energies)\n",
    "\n",
    "    f = Model(inputs=[X, s0, c0], outputs = outputs)\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
    "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
    "\n",
    "    r = f([encoded, s0, c0])\n",
    "        \n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0, t_prime]\n",
    "\n",
    "    # Normalize attention map\n",
    "    row_max = attention_map.max(axis=1)\n",
    "    attention_map = attention_map / row_max[:, None]\n",
    "\n",
    "    prediction = modelx.predict([encoded, s0, c0])\n",
    "    \n",
    "    predicted_text = []\n",
    "    for i in range(len(prediction)):\n",
    "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
    "        \n",
    "    predicted_text = list(predicted_text)\n",
    "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "    text_ = list(text)\n",
    "    \n",
    "    # get the lengths of the string\n",
    "    input_length = len(text)\n",
    "    output_length = Ty\n",
    "    \n",
    "    # Plot the attention_map\n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(8, 8.5))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "    ax.set_yticklabels(predicted_text[:output_length])\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "    ax.grid()\n",
    "    \n",
    "    return attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x612 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coursera]",
   "language": "python",
   "name": "conda-env-coursera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
