{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Network Application: Question Answering\n",
    "\n",
    "Question answering (QA) is a task of natural language processing that aims to automatically answer questions. The goal of *extractive* QA is to identify the portion of the text that contains the answer to a question. For example, when tasked with answering the question 'When will Jane go to Africa?' given the text data 'Jane visits Africa in September', the question answering model will highlight 'September'.\n",
    "\n",
    "\n",
    "<font color='blue'>Approach:  \n",
    "* Perform extractive Question Answering \n",
    "* Fine-tune a pre-trained transformer model to a custom dataset\n",
    "* Implement a QA model in TensorFlow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Run the following cell to load the [QA bAbI dataset](https://research.fb.com/downloads/babi/), which is one of the bAbI datasets generated by Facebook AI Research to advance natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset and print the first example in the training set\n",
    "babi_dataset = load_from_disk('data/nlp_qa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1), (1000, 1))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_dataset['train'].shape, babi_dataset['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': {'answer': ['', '', 'office'],\n",
       "  'id': ['1', '2', '3'],\n",
       "  'supporting_ids': [[], [], ['1']],\n",
       "  'text': ['The office is north of the kitchen.',\n",
       "   'The garden is south of the kitchen.',\n",
       "   'What is north of the kitchen?'],\n",
       "  'type': [0, 0, 1]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': {'answer': ['', '', 'kitchen'],\n",
       "  'id': ['1', '2', '3'],\n",
       "  'supporting_ids': [[], [], ['1']],\n",
       "  'text': ['The kitchen is west of the garden.',\n",
       "   'The hallway is west of the kitchen.',\n",
       "   'What is the garden east of?'],\n",
       "  'type': [0, 0, 1]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = babi_dataset['train'][1]\n",
    "example['story']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 0, 1]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and see if the entire dataset of stories has this format.\n",
    "\n",
    "type_set = set()\n",
    "for example in babi_dataset['train']:\n",
    "    if str(example['story']['type']) not in type_set:\n",
    "        type_set.add(str(example['story']['type'] ))\n",
    "type_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['story.answer', 'story.id', 'story.supporting_ids', 'story.text', 'story.type'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['story.answer', 'story.id', 'story.supporting_ids', 'story.text', 'story.type'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make the data easier to work with,\n",
    "# flatten the dataset to transform it from a dictionary structure to a table structure.\n",
    "\n",
    "flat_babi = babi_dataset.flatten()\n",
    "flat_babi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story.answer': ['', '', 'kitchen'],\n",
       " 'story.id': ['1', '2', '3'],\n",
       " 'story.supporting_ids': [[], [], ['1']],\n",
       " 'story.text': ['The kitchen is west of the garden.',\n",
       "  'The hallway is west of the kitchen.',\n",
       "  'What is the garden east of?'],\n",
       " 'story.type': [0, 0, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_babi['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_and_facts(m):\n",
    "    dic = {}\n",
    "    dic['question'] = m['story.text'][2]\n",
    "    dic['sentences'] = ' '.join([m['story.text'][0], m['story.text'][1]])\n",
    "    dic['answer'] = m['story.answer'][2]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function get_question_and_facts at 0x000002036C7E6438> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcd17e9830a49be9431e2c0ab776cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac8ed6aeb684102a2399744af60e578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed = flat_babi.map(get_question_and_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'bedroom',\n",
       " 'question': 'What is north of the garden?',\n",
       " 'sentences': 'The garden is north of the office. The bedroom is north of the garden.',\n",
       " 'story.answer': ['', '', 'bedroom'],\n",
       " 'story.id': ['1', '2', '3'],\n",
       " 'story.supporting_ids': [[], [], ['2']],\n",
       " 'story.text': ['The garden is north of the office.',\n",
       "  'The bedroom is north of the garden.',\n",
       "  'What is north of the garden?'],\n",
       " 'story.type': [0, 0, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['train'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of extractive QA is to find the **part of the text** that contains the answer to the question. We will identify the position of the answer using start and end string indices of the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_idx(m):\n",
    "    str_idx = m['sentences'].find(m['answer'])\n",
    "    end_idx = str_idx + len(m['answer'])\n",
    "    return {'str_idx':str_idx, 'end_idx': end_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64f0488794a484b85ea59b89a74e2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c8cc8bfa944fb496d9ceb0a1edb877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed = processed.map(get_start_end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'bedroom',\n",
       " 'end_idx': 46,\n",
       " 'question': 'What is north of the garden?',\n",
       " 'sentences': 'The garden is north of the office. The bedroom is north of the garden.',\n",
       " 'story.answer': ['', '', 'bedroom'],\n",
       " 'story.id': ['1', '2', '3'],\n",
       " 'story.supporting_ids': [[], [], ['2']],\n",
       " 'story.text': ['The garden is north of the office.',\n",
       "  'The bedroom is north of the garden.',\n",
       "  'What is north of the garden?'],\n",
       " 'story.type': [0, 0, 1],\n",
       " 'str_idx': 39}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['train'][2]['sentences'].find('bedroom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (1000, 10), 'test': (1000, 10)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Align with ðŸ¤— Library\n",
    "\n",
    "Now we have all the data to train a Transformer model to perform Question Answering! \n",
    "* To feed text data to a Transformer model, we will need to tokenize the input using a [ðŸ¤— Transformer tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html). \n",
    "* It is crucial that the tokenizer we use must match the Transformer model type we are using - ðŸ¤— [DistilBERT fast tokenizer](https://huggingface.co/transformers/model_doc/distilbert.html), in this case, which standardizes the length of sequence to 512 and pads with zeros.\n",
    "\n",
    "**Operational Note**: Transformer models are often trained by tokenizers that split words into subwords. For instance, the word 'Africa' might get split into multiple subtokens. This can create some misalignment between the list of tags for the dataset and the list of labels generated by the tokenizer, since the tokenizer can split one word into several, or add special tokens. Before processing, it is important that we align the start and end indices with the tokens associated with the target answer word with a `tokenize_and_align()` function. In this case, since we are interested in the start and end indices of the answer, we will want to align the index of the sentence to match the index of the token for a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('pretrainedmodel/nlp_transformer/tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_align(example):\n",
    "    encoding = tokenizer(example['sentences'], example['question'], truncation=True, \n",
    "                         padding=True, max_length=tokenizer.model_max_length)\n",
    "    start_positions = encoding.char_to_token(example['str_idx'])\n",
    "    end_positions = encoding.char_to_token(example['end_idx']-1)\n",
    "    if start_positions is None:\n",
    "        start_positions = tokenizer.model_max_length\n",
    "    if end_positions is None:\n",
    "        end_positions = tokenizer.model_max_length\n",
    "    \n",
    "    return {'input_ids': encoding['input_ids'],\n",
    "            'attention_mask': encoding['attention_mask'],\n",
    "            'start_positions': start_positions,\n",
    "            'end_positions': end_positions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'office',\n",
       " 'end_idx': 10,\n",
       " 'question': 'What is north of the kitchen?',\n",
       " 'sentences': 'The office is north of the kitchen. The garden is south of the kitchen.',\n",
       " 'story.answer': ['', '', 'office'],\n",
       " 'story.id': ['1', '2', '3'],\n",
       " 'story.supporting_ids': [[], [], ['1']],\n",
       " 'story.text': ['The office is north of the kitchen.',\n",
       "  'The garden is south of the kitchen.',\n",
       "  'What is north of the kitchen?'],\n",
       " 'story.type': [0, 0, 1],\n",
       " 'str_idx': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 9\n",
      "2 2\n",
      "{'input_ids': [101, 1996, 2436, 2003, 2167, 1997, 1996, 3829, 1012, 1996, 3871, 2003, 2148, 1997, 1996, 3829, 1012, 102, 2054, 2003, 2167, 1997, 1996, 3829, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# What does the function do?\n",
    "temp = processed['train'][0]\n",
    "display(temp)\n",
    "\n",
    "encoding = tokenizer(temp['sentences'], temp['question'], truncation=True, \n",
    "                         padding=True, max_length=tokenizer.model_max_length)\n",
    "start_positions = encoding.char_to_token(temp['str_idx'])\n",
    "end_positions = encoding.char_to_token(temp['end_idx']-1)\n",
    "print(temp['str_idx'], temp['end_idx']-1)\n",
    "print(start_positions, end_positions)\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96b4587ab0b45d88d9e76fc61b39a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ccb53654374ee98d30cbaf5b4fa195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qa_dataset = processed.map(tokenize_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset = qa_dataset.remove_columns(['story.answer', 'story.id', 'story.supporting_ids', 'story.text', 'story.type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'office',\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'end_idx': 10,\n",
       " 'end_positions': 2,\n",
       " 'input_ids': [101,\n",
       "  1996,\n",
       "  2436,\n",
       "  2003,\n",
       "  2167,\n",
       "  1997,\n",
       "  1996,\n",
       "  3829,\n",
       "  1012,\n",
       "  1996,\n",
       "  3871,\n",
       "  2003,\n",
       "  2148,\n",
       "  1997,\n",
       "  1996,\n",
       "  3829,\n",
       "  1012,\n",
       "  102,\n",
       "  2054,\n",
       "  2003,\n",
       "  2167,\n",
       "  1997,\n",
       "  1996,\n",
       "  3829,\n",
       "  1029,\n",
       "  102],\n",
       " 'question': 'What is north of the kitchen?',\n",
       " 'sentences': 'The office is north of the kitchen. The garden is south of the kitchen.',\n",
       " 'start_positions': 2,\n",
       " 'str_idx': 4}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset['train'][0]\n",
    "# Kitchen = 3829, North = 2167, Is = 2003, The = 1996, Of = 1997, '.' = 1012, \"'\" = 101/102\n",
    "# answer = 'office' which is at index=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pre-trained Model\n",
    "\n",
    "Now that we've finished tokenizing and aligning data, it can be fed to a pre-trained ðŸ¤— Transformer model - we use a **DistilBERT model**, which matches the tokenizer used to preprocess your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = qa_dataset['train']\n",
    "test_ds = qa_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at pretrainedmodel/nlp_transformer/DistilBertQATF.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForQuestionAnswering\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained('pretrainedmodel/nlp_transformer/DistilBertQATF', \n",
    "                                                         return_dict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation\n",
    "\n",
    "**Operational Note**:\n",
    "* In the TensorFlow implementation, we will have to set the data format type to tensors, which may create ragged tensors (tensors of different lengths). \n",
    "* We will have to convert the ragged tensors to normal tensors using the `to_tensor()` method, which pads the tensors and sets the dimensions to `[None, tokenizer.model_max_length]` so we can feed different size tensors into the model based on the batch size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_return = ['input_ids','attention_mask', 'start_positions', 'end_positions']\n",
    "\n",
    "train_ds.set_format(type='tf', columns=columns_to_return)\n",
    "\n",
    "train_features = {x: train_ds[x].to_tensor(default_value=0, shape=[None, tokenizer.model_max_length])\n",
    "                  for x in ['input_ids', 'attention_mask']}\n",
    "train_labels = {\"start_positions\": tf.reshape(train_ds['start_positions'], shape=[-1,1]),\n",
    "                'end_positions': tf.reshape(train_ds['end_positions'], shape=[-1,1])}\n",
    "\n",
    "train_tfdataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "**Operational Note**:\n",
    "* Create a custom training function using tf.GradientTape() - it records the operations performed during forward prop for automatic differentiation during backprop.\n",
    "* Target two loss functions, one for the start index and one for the end index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0\n",
      "Training loss (for one batch) at step 0: 6.4653\n",
      "Training loss (for one batch) at step 20: 1.3122\n",
      "Training loss (for one batch) at step 40: 0.9882\n",
      "Training loss (for one batch) at step 60: 0.8768\n",
      "Training loss (for one batch) at step 80: 0.5850\n",
      "Training loss (for one batch) at step 100: 0.2007\n",
      "Training loss (for one batch) at step 120: 0.6216\n",
      "Starting epoch: 1\n",
      "Training loss (for one batch) at step 0: 0.6460\n",
      "Training loss (for one batch) at step 20: 0.1893\n",
      "Training loss (for one batch) at step 40: 0.5078\n",
      "Training loss (for one batch) at step 60: 0.3546\n",
      "Training loss (for one batch) at step 80: 0.1946\n",
      "Training loss (for one batch) at step 100: 0.0993\n",
      "Training loss (for one batch) at step 120: 0.4973\n",
      "Starting epoch: 2\n",
      "Training loss (for one batch) at step 0: 0.4075\n",
      "Training loss (for one batch) at step 20: 0.2040\n",
      "Training loss (for one batch) at step 40: 0.5305\n",
      "Training loss (for one batch) at step 60: 0.2548\n",
      "Training loss (for one batch) at step 80: 0.1245\n",
      "Training loss (for one batch) at step 100: 0.0969\n",
      "Training loss (for one batch) at step 120: 0.6247\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "loss_fn1 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Starting epoch: %d\"% epoch )\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_tfdataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            answer_start_scores, answer_end_scores = model(x_batch_train)\n",
    "            loss_start = loss_fn1(y_batch_train['start_positions'], answer_start_scores)\n",
    "            loss_end   = loss_fn2(y_batch_train['end_positions']  , answer_end_scores)\n",
    "            loss = 0.5 * (loss_start + loss_end)\n",
    "        losses.append(loss)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(\"Training loss (for one batch) at step %d: %.4f\"% (step, \n",
    "                                                                   float(loss_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24327dc6d48>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UaM5pY9u8EW"
   },
   "source": [
    "---\n",
    "## PyTorch implementation\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is an open source machine learning framework developed by Facebook's AI Research lab that can be used for computer vision and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nD9akXoXxMjd"
   },
   "source": [
    "### Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]),\n",
       " 'end_positions': tensor(2),\n",
       " 'input_ids': tensor([ 101, 1996, 2436, 2003, 2167, 1997, 1996, 3829, 1012, 1996, 3871, 2003,\n",
       "         2148, 1997, 1996, 3829, 1012,  102, 2054, 2003, 2167, 1997, 1996, 3829,\n",
       "         1029,  102]),\n",
       " 'start_positions': tensor(2)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JxMYWSG173ch"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "columns_to_return = ['input_ids','attention_mask', 'start_positions', 'end_positions']\n",
    "train_ds.set_format(type='pt', columns=columns_to_return)   # type = pytorch, tensorflow, numpy etc.\n",
    "test_ds.set_format(type='pt', columns=columns_to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeuzZKlPHAAQ"
   },
   "source": [
    "For the accuracy metrics for the PyTorch implementation, we will use F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aD9tDpZfJsIB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    start_labels = pred.label_ids[0]\n",
    "    end_labels   = pred.label_ids[1]\n",
    "    start_preds  = pred.predictions[0].argmax(-1)\n",
    "    end_preds    = pred.predictions[1].argmax(-1)\n",
    "    \n",
    "    f1_start = f1_score(start_labels, start_preds, average='macro')\n",
    "    f1_end   = f1_score(end_labels, end_preds, average='macro')\n",
    "    \n",
    "    return {'f1_start': f1_start,\n",
    "            'f1_end': f1_end}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model # We delete the tensorflow model to avoid memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXFCsNcY79jx",
    "outputId": "09af112f-e1e9-4a47-c988-37ee2a068df2"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "pytorch_model = DistilBertForQuestionAnswering.from_pretrained(\"pretrainedmodel/nlp_transformer/DistilBertQApytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCUdMmCxHP6_"
   },
   "source": [
    "Instead of a custom training loop, you will use the [ðŸ¤— Trainer](https://huggingface.co/transformers/main_classes/trainer.html), which contains a basic training loop and is fairly easy to implement in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "1htmS3TV-2Bk",
    "outputId": "cc21bfbb-da09-47f9-ee16-7db0096d35e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 03:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.416300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.337700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.5834623311360677, metrics={'train_runtime': 233.4976, 'train_samples_per_second': 1.606, 'total_flos': 31058547624000, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='results',            # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=20,                 # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=None,                # directory for storing logs\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=pytorch_model,                 # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_ds,              # training dataset\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics      # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "lDzbm7vzAiPJ",
    "outputId": "7cd62f51-a04b-4583-bc0e-e459813d3103"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31048983335494995,\n",
       " 'eval_f1_start': 0.8231819375164086,\n",
       " 'eval_f1_end': 0.8175549301161046,\n",
       " 'eval_runtime': 13.8539,\n",
       " 'eval_samples_per_second': 72.182,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAgrcs2pHvVu"
   },
   "source": [
    "Now it is time to ask the PyTorch model a question! \n",
    "* Before testing the model with a question, we can tell PyTorch to send our model and inputs to the GPU if the machine has one, or the CPU if it does not. \n",
    "* We can then proceed to tokenize the input and create PyTorch tensors and send them to the device. \n",
    "* The rest of the pipeline is relatively similar to the one we implemented for TensorFlow.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfBe9AFABqUr",
    "outputId": "b5ca6039-8ce2-4e75-9161-1c96a0f39425"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "pytorch_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text     = 'The balcony is east of the hallway. The garden is south of the bedroom.'\n",
    "question = 'What is east of the hallway?'\n",
    "\n",
    "input_dict = tokenizer(text, question, return_tensors='pt')\n",
    "\n",
    "input_ids      = input_dict['input_ids'].to(device)\n",
    "attention_mask = input_dict['attention_mask'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1996, 11673,  2003,  2264,  1997,  1996,  6797,  1012,  1996,\n",
       "          3871,  2003,  2148,  1997,  1996,  5010,  1012,   102,  2054,  2003,\n",
       "          2264,  1997,  1996,  6797,  1029,   102]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is east of the hallway? Balcony\n"
     ]
    }
   ],
   "source": [
    "outputs = pytorch_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "start_logits = outputs[0]\n",
    "end_logits = outputs[1]\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_logits, 1)[0] : torch.argmax(end_logits, 1)[0]+1])\n",
    "\n",
    "print(question, answer.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8tAV-584vKE"
   },
   "source": [
    "<font color='blue'><b>Takeaways:</b>\n",
    "- Transformer models are often trained by tokenizers that split words into subwords.\n",
    "  - Before processing, it is important to align the start and end indices with the tokens associated with the target answer word.\n",
    "- PyTorch is a relatively light and easy to implement framework that can make rapid prototyping easier, while TensorFlow has advantages in scaling and is more widely used in production\n",
    "  - `tf.GradientTape` allows us to build custom training loops in TensorFlow\n",
    "  - The `Trainer` API in PyTorch gives a basic training loop that is compatible with ðŸ¤— models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coursera]",
   "language": "python",
   "name": "conda-env-coursera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
